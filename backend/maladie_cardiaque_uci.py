# -*- coding: utf-8 -*-
"""maladie_cardiaque_uci.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1imw1Jha4r-w4qzReCbtka6YDLoJWGRkY
"""

!pip install pandas numpy matplotlib seaborn scikit-learn
!pip install pydrive
!pip install oauth2client
!pip install xgboost lightgbm

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import gdown
import joblib
import shap
import warnings
warnings.filterwarnings('ignore', category=FutureWarning)

from sklearn.model_selection import train_test_split,cross_val_score,GridSearchCV
from sklearn.preprocessing import LabelEncoder,StandardScaler,label_binarize
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix,precision_score, recall_score, f1_score,roc_auc_score, roc_curve
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA

# Importation des bibliothèques
from xgboost import XGBClassifier
from lightgbm import LGBMClassifier

from pydrive.auth import GoogleAuth
from pydrive.drive import GoogleDrive
from google.colab import auth
from oauth2client.client import GoogleCredentials






# Remplacez par le lien partagé de Google Drive
drive_link = "https://drive.google.com/file/d/17hvLnQJXuhww5CY410D_feBhFsKwy-U-/view?usp=sharing"

# Convertir le lien en lien téléchargeable
file_id = drive_link.split("/d/")[1].split("/view")[0]
download_url = f"https://drive.google.com/uc?id={file_id}"

# Télécharger le fichier CSV
output_file = "data.csv"
gdown.download(download_url, output_file, quiet=False)

# Charger le fichier CSV avec Pandas
data = pd.read_csv(output_file)

# Afficher les premières lignes
print("Aperçu des données :")
print(data.head())

#Aperçu général
# Dimensions du jeu de données
print(f"Dimensions : {data.shape}")

# Résumé des colonnes et types de données
print("Résumé des colonnes :")
data.info()

# Résumé statistique
print("Résumé statistique :")
data.describe()

#Vérification des valeurs manquantes
print("Valeurs manquantes :")
print(data.isnull().sum())

#Distribution des classes
# 'target' est souvent la colonne représentant la présence de maladies cardiaques
sns.countplot(x=data['num'], data=data)
plt.title("Répartition des classes (maladie cardiaque présente/absente)")
plt.show()

# Corrélations entre les variables
# Sélectionner uniquement les colonnes numériques
numerical_data = data.select_dtypes(include=['float64', 'int64'])

# Afficher la matrice de corrélation
plt.figure(figsize=(12, 8))
sns.heatmap(numerical_data.corr(), annot=True, fmt=".2f", cmap="coolwarm")
plt.title("Matrice de corrélation")
plt.show()

#Étape 4 : Nettoyage des Données
#Suppression des doublons
# Vérifier et supprimer les doublons
print(f"Taille initiale : {data.shape}")
print(f"Doublons avant : {data.duplicated().sum()}")
data = data.drop_duplicates()
print(f"Doublons après : {data.duplicated().sum()}")

#Gérer les valeurs aberrantes (si détectées)
# Visualisation des valeurs aberrantes pour certaines colonnes
sns.boxplot(x=data['chol'])  # Exemple pour le cholestérol
plt.title("Distribution des valeurs de cholestérol")
plt.show()

# Suppression des valeurs aberrantes (exemple pour cholestérol < 600)
data = data[data['chol'] < 600]

#Encodage des variables catégoriques (si présent)
# Exemple : Si des colonnes catégoriques existent
# data['column_name'] = data['column_name'].astype('category').cat.codes

#Étape 5 : Préparation pour la Modélisation
#Séparation des caractéristiques et de la cible
X = data.drop('num', axis=1)  # Caractéristiques
y = data['num']              # Cible

#Division des données
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

print(f"Taille des ensembles :")
print(f"Entraînement : {X_train.shape}, Test : {X_test.shape}")

#Normalisation des données
# Étape 1 : Encoder les variables catégorielles
label_encoder = LabelEncoder()

for col in X.columns:
    if X[col].dtype == 'object':  # Vérifier si la colonne est catégorielle
        X[col] = label_encoder.fit_transform(X[col])

# Étape 2 : Diviser les données en train et test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

#Étape 6 : Enregistrement et Préparation pour la Modélisation
# Sauvegarder les ensembles traités
pd.DataFrame(X_train).to_csv('X_train.csv', index=False)
pd.DataFrame(X_test).to_csv('X_test.csv', index=False)
pd.DataFrame(y_train).to_csv('y_train.csv', index=False)
pd.DataFrame(y_test).to_csv('y_test.csv', index=False)

"""Entraînement et Évaluation"""

# Remplir les NaN avec la moyenne pour les colonnes numériques
imputer = SimpleImputer(strategy='mean')

# Appliquer l'imputation sur X_train et X_test

X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Vérifier que toutes les valeurs NaN sont traitées
print(f"NaN dans X_train après traitement : {np.isnan(X_train).sum()}")
print(f"NaN dans X_test après traitement : {np.isnan(X_test).sum()}")

# Entraînement et Évaluation
# Régression Logistique
# Modèle de régression logistique
log_model = LogisticRegression(random_state=42)
log_model.fit(X_train, y_train)

# Prédiction
y_pred_log = log_model.predict(X_test)

# Évaluation
print("Performance de la Régression Logistique :")
print(f"Accuracy : {accuracy_score(y_test, y_pred_log):.2f}")
print(classification_report(y_test, y_pred_log))

# Matrice de confusion
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred_log), annot=True, fmt='d', cmap='Blues')
plt.title("Matrice de Confusion - Régression Logistique")
plt.xlabel("Prédictions")
plt.ylabel("Vérités")
plt.show()

# Modèle de l'Arbre de Décision
tree_model = DecisionTreeClassifier(random_state=42, max_depth=5)
tree_model.fit(X_train, y_train)

# Prédiction
y_pred_tree = tree_model.predict(X_test)

# Évaluation
print("Performance de l'Arbre de Décision :")
print(f"Accuracy : {accuracy_score(y_test, y_pred_tree):.2f}")
print(classification_report(y_test, y_pred_tree))

# Matrice de confusion
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred_tree), annot=True, fmt='d', cmap='Greens')
plt.title("Matrice de Confusion - Arbre de Décision")
plt.xlabel("Prédictions")
plt.ylabel("Vérités")
plt.show()

# Modèle de la Forêt Aléatoire
rf_model = RandomForestClassifier(random_state=42, n_estimators=100, max_depth=10)
rf_model.fit(X_train, y_train)

# Prédiction
y_pred_rf = rf_model.predict(X_test)

# Évaluation
print("Performance de la Forêt Aléatoire :")
print(f"Accuracy : {accuracy_score(y_test, y_pred_rf):.2f}")
print(classification_report(y_test, y_pred_rf))

# Matrice de confusion
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred_rf), annot=True, fmt='d', cmap='Oranges')
plt.title("Matrice de Confusion - RandomForest ")
plt.xlabel("Prédictions")
plt.ylabel("Vérités")
plt.show()

# Modèle XGBoost
xgb_model = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='mlogloss')
xgb_model.fit(X_train, y_train)

# Prédiction
y_pred_xgb = xgb_model.predict(X_test)

# Évaluation
print("Performance de XGBoost :")
print(f"Accuracy : {accuracy_score(y_test, y_pred_xgb):.2f}")
print(classification_report(y_test, y_pred_xgb))

# Matrice de confusion
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred_xgb), annot=True, fmt='d', cmap='Purples')
plt.title("Matrice de Confusion - XGBoost")
plt.xlabel("Prédictions")
plt.ylabel("Vérités")
plt.show()

# Modèle LightGBM
lgbm_model = LGBMClassifier(random_state=42,verbose=-1)

lgbm_model.fit(X_train, y_train)

# Prédiction
y_pred_lgbm = lgbm_model.predict(X_test,)

# Évaluation
print("Performance de LightGBM :")
print(f"Accuracy : {accuracy_score(y_test, y_pred_lgbm):.2f}")
print(classification_report(y_test, y_pred_lgbm))

# Matrice de confusion
plt.figure(figsize=(6, 4))
sns.heatmap(confusion_matrix(y_test, y_pred_lgbm), annot=True, fmt='d', cmap='Reds')
plt.title("Matrice de Confusion - LightGBM")
plt.xlabel("Prédictions")
plt.ylabel("Vérités")
plt.show()

# Comparaison des scores
models = {
    "Logistic Regression": accuracy_score(y_test, y_pred_log),
    "Decision Tree": accuracy_score(y_test, y_pred_tree),
    "Random Forest": accuracy_score(y_test, y_pred_rf),
    "XGBoost": accuracy_score(y_test, y_pred_xgb),
    "LightGBM": accuracy_score(y_test, y_pred_lgbm)
}

# Comparer les résultats
print("\nRésumé des performances des modèles :")
for model_name, acc in models.items():
    print(f"{model_name}: {acc:.2f}")

# Visualisation des performances
plt.figure(figsize=(8, 6))
plt.bar(models.keys(), models.values(), color=['blue', 'green', 'orange', 'purple', 'red'])
plt.title("Comparaison des Performances des Modèles (Accuracy)")
plt.xlabel("Modèle")
plt.ylabel("Accuracy")
plt.xticks(rotation=45)
plt.show()

# Métriques détaillées

print("Métriques détaillées pour la Forêt Aléatoire :")
print(f"Précision : {precision_score(y_test, y_pred_rf, average='weighted'):.2f}")
print(f"Rappel : {recall_score(y_test, y_pred_rf, average='weighted'):.2f}")
print(f"F1-Score : {f1_score(y_test, y_pred_rf, average='weighted'):.2f}")

# Binarisation des étiquettes pour calcul multiclass ROC
y_test_bin = label_binarize(y_test, classes=[0, 1, 2, 3, 4])
y_proba = rf_model.predict_proba(X_test)

# AUC
auc_score = roc_auc_score(y_test_bin, y_proba, multi_class='ovr')
print(f"AUC Score : {auc_score:.2f}")

# Importance des caractéristiques
feature_importances = rf_model.feature_importances_
features = pd.DataFrame({'Caractéristique': X.columns, 'Importance': feature_importances})
features = features.sort_values(by='Importance', ascending=False)
print(features)

# Graphique des importances
#Nous avons identifié les facteurs clés influençant la prédiction, comme le cholestérol et la fréquence cardiaque.
plt.figure(figsize=(10, 6))
plt.barh(features['Caractéristique'], features['Importance'], color='skyblue')
plt.xlabel("Importance")
plt.title("Importance des Caractéristiques - Random Forest")
plt.show()

scores = cross_val_score(rf_model, X, y, cv=5, scoring='accuracy')
print(f"Scores de validation croisée : {scores}")
print(f"Moyenne des scores : {scores.mean():.2f}")

# Identifier les erreurs

errors = X_test[y_test != y_pred_rf]
error_labels = y_test[y_test != y_pred_rf]
print("Échantillons mal prédits :", errors)

param_grid = {
    'n_estimators': [100, 200, 300],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(rf_model, param_grid, cv=3, scoring='accuracy')
grid_search.fit(X_train, y_train)

print(f"Meilleurs paramètres : {grid_search.best_params_}")

print("Rapport de classification détaillé :")
print(classification_report(y_test, rf_model.predict(X_test)))

# Créer un DataFrame pour une analyse simple
X_test_df = pd.DataFrame(X_test)
X_test_df['True_Label'] = y_test
X_test_df['Predicted_Label'] = rf_model.predict(X_test)

# Filtrer les échantillons mal classifiés
misclassified_samples = X_test_df[X_test_df['True_Label'] != X_test_df['Predicted_Label']]

# Moyenne des caractéristiques des échantillons mal classifiés
print(misclassified_samples.mean())

# PCA pour réduire à 2 dimensions
pca = PCA(n_components=2)
X_pca = pca.fit_transform(X_test)

# Identifier les indices mal classifiés
misclassified_indices = (y_test != rf_model.predict(X_test))

# Visualisation
#Les échantillons mal classifiés ont été examinés pour comprendre les limites des modèles.
plt.figure(figsize=(8, 6))
plt.scatter(X_pca[~misclassified_indices, 0], X_pca[~misclassified_indices, 1], c='green', label='Correct')
plt.scatter(X_pca[misclassified_indices, 0], X_pca[misclassified_indices, 1], c='red', label='Misclassified')
plt.legend()
plt.title("Visualisation des échantillons mal classifiés")
plt.show()

# Sauvegarder les modèle
joblib.dump(rf_model, 'heart_disease_rf_model.pkl')
joblib.dump(xgb_model, 'heart_disease_xgb_model.pkl')
joblib.dump(lgbm_model, 'heart_disease_lgbm_model.pkl')


print("Le modèle le plus performant a été sauvegardé sous 'heart_disease_rf_model.pkl'.")
print("Le modèle le plus performant a été sauvegardé sous 'heart_disease_xgb_model.pkl'.")
print("Le modèle le plus performant a été sauvegardé sous 'heart_disease_lgbm_model.pkl'.")